{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aashigupta1288/Career_Recommendation_System/blob/main/model_train_video_fully_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ_OqiI2xhqD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "uploaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNOt5upnxhqE"
      },
      "outputs": [],
      "source": [
        "! pip install DeepFace  librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsR5-1WJxhqF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaB922LxxhqF"
      },
      "outputs": [],
      "source": [
        "# For Jupyter widget upload\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8328bDpcxhqF"
      },
      "outputs": [],
      "source": [
        "# --- Step 1: Load and preprocess CSV ---\n",
        "\n",
        "df = pd.read_csv('updated_data.csv')\n",
        "\n",
        "# Clean and preprocess Career Role column\n",
        "df = df.dropna(subset=['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism', 'Career Role'])\n",
        "df['Career Role'] = df['Career Role'].astype(str).apply(lambda x: [role.strip() for role in x.split(',')])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFSfQCquxhqF"
      },
      "outputs": [],
      "source": [
        "# Features and target\n",
        "features = ['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']\n",
        "X = df[features].values\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSgXdpU4xhqF"
      },
      "outputs": [],
      "source": [
        "# Multi-label binarize target\n",
        "mlb = MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(df['Career Role'])\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62_9m7XfxhqG"
      },
      "outputs": [],
      "source": [
        "# --- Step 2: Train multi-label classifier ---\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "base_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf = MultiOutputClassifier(base_clf)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "print(\"Classification report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=mlb.classes_, zero_division=0))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijyqLt1gxhqG"
      },
      "outputs": [],
      "source": [
        "# Save model and encoders for reuse\n",
        "joblib.dump(clf, 'career_big5_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "joblib.dump(mlb, 'mlb.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1qLn9xcxhqG"
      },
      "outputs": [],
      "source": [
        "# --- Step 3: Prediction function ---\n",
        "\n",
        "def predict_career(openness, conscientiousness, extraversion, agreeableness, neuroticism):\n",
        "    traits = np.array([[openness, conscientiousness, extraversion, agreeableness, neuroticism]])\n",
        "    traits_scaled = scaler.transform(traits)\n",
        "    pred = clf.predict(traits_scaled)\n",
        "    careers = mlb.inverse_transform(pred)\n",
        "    return careers[0] if careers else []\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0xhJ9adxhqG"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import librosa\n",
        "from deepface import DeepFace\n",
        "import moviepy.editor as mp\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "\n",
        "def extract_video_features(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    embeddings = []\n",
        "\n",
        "    # Iterate over the video frames\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Extract facial embeddings using DeepFace\n",
        "        try:\n",
        "            result = DeepFace.represent(frame, enforce_detection=False)\n",
        "            embeddings.append(result[0]['embedding'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error in processing frame: {e}\")\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # If we have extracted multiple frames, average the embeddings\n",
        "    if embeddings:\n",
        "        return np.mean(embeddings, axis=0)\n",
        "    return np.zeros(128)  # Default value if no face is detected\n",
        "\n",
        "def extract_audio_features_from_video(video_path):\n",
        "    # Extract audio from video using moviepy\n",
        "    video = mp.VideoFileClip(video_path)\n",
        "    audio = video.audio\n",
        "    audio_path = 'extracted_audio.wav'\n",
        "    audio.write_audiofile(audio_path)\n",
        "\n",
        "    # Extract MFCCs (Mel Frequency Cepstral Coefficients) as audio features\n",
        "    y, sr = librosa.load(audio_path, sr=None)\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    mfccs_mean = np.mean(mfccs, axis=1)  # Take the mean of each MFCC coefficient across the audio\n",
        "\n",
        "    return mfccs_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfiiyrjSxhqG"
      },
      "outputs": [],
      "source": [
        "def extract_traits_from_video(video_path):\n",
        "    print(f\"Processing video for trait extraction: {video_path}\")\n",
        "\n",
        "    # Extract features from video (face embeddings)\n",
        "    video_features = extract_video_features(video_path)\n",
        "    print(f\"Extracted video features (face embeddings): {video_features.shape}\")\n",
        "\n",
        "    # Extract audio features from video\n",
        "    audio_features = extract_audio_features_from_video(video_path)\n",
        "    print(f\"Extracted audio features (MFCCs): {audio_features.shape}\")\n",
        "\n",
        "    # Combine both video and audio features\n",
        "    combined_features = np.concatenate((video_features, audio_features), axis=0)\n",
        "    return combined_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqxuripbxhqH"
      },
      "outputs": [],
      "source": [
        "# --- Step 4: Placeholder for Big Five trait extraction from video ---\n",
        "\n",
        "def extract_big5_traits_from_video(video_path):\n",
        "\n",
        "    print(f\"Processing video for trait extraction: {video_path}\")\n",
        "    return np.random.uniform(2, 4, size=5)\n",
        "\n",
        "\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='.mp4, .avi, .mov',\n",
        "    multiple=False,\n",
        "    description='Upload Video'\n",
        ")\n",
        "display(uploader)\n",
        "\n",
        "def on_upload_change(change):\n",
        "    if uploader.value:\n",
        "        for filename, file_info in uploader.value.items():\n",
        "            # Save uploaded video locally\n",
        "            with open(filename, 'wb') as f:\n",
        "                f.write(file_info['content'])\n",
        "            print(f\"Saved uploaded video as {filename}\")\n",
        "\n",
        "            # Extract Big Five traits from the video (placeholder)\n",
        "            traits = extract_big5_traits_from_video(filename)\n",
        "            print(f\"Extracted Big Five traits: {traits}\")\n",
        "\n",
        "            # Predict career roles\n",
        "            predicted_roles = predict_career(*traits)\n",
        "            print(f\"Predicted career roles: {predicted_roles}\")\n",
        "\n",
        "uploader.observe(on_upload_change, names='value')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ6uUivQxhqH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import hamming_loss\n",
        "print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzrQL8vWxhqH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Exact Match Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}